apiVersion: v1
kind: ConfigMap
metadata:
  name: hadoop-config
  namespace: bigdata 
data:
  core-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration>
      <property>
        <name>fs.defaultFS</name>
        <value>hdfs://namenode-headless:8020</value>
      </property> 
      <property>
        <name>hadoop.tmp.dir</name>
        <value>/data/hadoop</value>
      </property>       
    </configuration>
  hdfs-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration>
      <property>
        <name>dfs.namenode.rpc-address</name>
        <value>namenode-headless:8020</value>
      </property>      
      <property>
        <name>dfs.replication</name>
        <value>1</value>
      </property>
      <property>
        <name>dfs.datanode.use.datanode.hostname</name>
        <value>false</value>
      </property>
      <property>
        <name>dfs.client.use.datanode.hostname</name>
        <value>false</value>
      </property>      
      <property>
          <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
          <value>false</value>
      </property>
      <!-- Bind to all interfaces -->
      <property>
          <name>dfs.namenode.rpc-bind-host</name>
          <value>0.0.0.0</value>
      </property>
      <property>
          <name>dfs.namenode.servicerpc-bind-host</name>
          <value>0.0.0.0</value>
      </property>
    </configuration>
  yarn-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration>
      <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>resourcemanager-headless</value>
      </property>         
      <property>
        <name>yarn.nodemanager.pmem-check-enabled</name>
        <value>false</value>
      </property>
      <property>
        <name>yarn.nodemanager.delete-debug-delay-sec</name>
        <value>600</value>
      </property>
      <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
      </property>
      <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
      </property>
    </configuration>
  mapred-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration>
      <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
      </property>
      <property>
        <name>mapreduce.map.env</name>
        <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
      </property>
      <property>
        <name>mapreduce.reduce.env</name>
        <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
      </property>
      <property>
        <name>mapreduce.am.env</name>
        <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
      </property>
    </configuration>
  hadoop-http-auth-signature-secret: |
    secret99
  bootstrap.sh: |
    #!/bin/bash
    : ${HADOOP_HOME:=/opt/hadoop}
    . $HADOOP_HOME/etc/hadoop/hadoop-env.sh
    . $HADOOP_HOME/etc/hadoop/yarn-env.sh
    # Directory to find config artifacts
    CONFIG_DIR="/tmp/hadoop-config"
    # Copy config files from volume mount
    for f in core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
        if [[ -e ${CONFIG_DIR}/$f ]]; then
          cp ${CONFIG_DIR}/$f $HADOOP_HOME/etc/hadoop/$f
        else
          echo "ERROR: Could not find $f in $CONFIG_DIR"
        exit 1
        fi
    done
    # copy hadoop-http-auth-signature-secret
    cp ${CONFIG_DIR}/hadoop-http-auth-signature-secret $HADOOP_HOME/hadoop-http-auth-signature-secret    
    # installing libraries if any - (resource urls added comma separated to the ACP system variable)
    cd $HADOOP_HOME/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -
    if [[ $2 == "namenode" ]]; then
        # dfs.namenode.name.dir
        if [ ! -d "/data/hadoop/dfs/name" ]; then
          mkdir -p /data/hadoop/dfs/name
          $HADOOP_HOME/bin/hdfs namenode -format -force -nonInteractive
        fi
        $HADOOP_HOME/sbin/hadoop-daemon.sh start namenode
    fi
    if [[ $2 == "datanode" ]]; then
        # dfs.datanode.data.dir
        if [ ! -d "/data/hadoop/dfs/data" ]; then
          mkdir -p /data/hadoop/dfs/data
        fi
        #  wait up to 30 seconds for namenode
        (while [[ $count -lt 15 && -z 'curl -sf http://namenode-headless:9870' ]]; do ((count=count+1)) ; echo "Waiting for namenode-headless" ; sleep 2; done && [[ $count -lt 15 ]])
        [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs namenode, exiting." && exit 1
        $HADOOP_HOME/sbin/hadoop-daemon.sh start datanode
    fi
    # Start ResourceManager
    if [[ $2 == "resourcemanager" ]]; then
        # yarn.resourcemanager.fs.state-store.uri
        if [ ! -d "/data/hadoop/yarn/system/rmstore" ]; then
          mkdir -p /data/hadoop/yarn/system/rmstore
        fi    
        # yarn.scheduler.configuration.fs.path
        if [ ! -d "/data/hadoop/yarn/system/schedconf" ]; then
          mkdir -p /data/hadoop/yarn/system/schedconf
        fi                    
        $HADOOP_HOME/sbin/yarn-daemon.sh start resourcemanager
    fi
    # Start NodeManager with ResourceManager check
    if [[ $2 == "nodemanager" ]]; then
        # yarn.nodemanager.local-dirs
        if [ ! -d "/data/hadoop/nm-local-dir" ]; then
          mkdir -p /data/hadoop/nm-local-dir
        fi
        # Wait for ResourceManager to be ready (port 8088 by default)
        #count=0
        #until [[ $count -ge 15 || $(curl -sf http://resourcemanager-headless:8088) ]]; do
        #    ((count=count+1))
        #    echo "Waiting for ResourceManager to be ready... attempt $count"
        #    sleep 2
        #done        
        #if [[ $count -ge 15 ]]; then
        #    echo "Timeout waiting for ResourceManager, exiting."
        #    exit 1
        #fi        
        echo "ResourceManager is ready. Starting NodeManager."
        $HADOOP_HOME/sbin/yarn-daemon.sh start nodemanager
    fi    
    if [[ $1 == "-d" ]]; then
        until find ${HADOOP_LOG_DIR} -mmin -1 | egrep -q '.*'; echo "'date': Waiting for logs..." ; do sleep 2 ; done
        tail -F ${HADOOP_LOG_DIR}/* &
        while true; do sleep 1000; done
    fi